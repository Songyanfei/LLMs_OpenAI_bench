# Naive_OpenAI_bench

## Overview
`Naive_OpenAI_bench` is a simple benchmarking script designed to evaluate model throughput and identify system bottlenecks in business scenarios. It utilizes a multi-threaded approach to send concurrent requests to large model services, providing insights into performance under different load conditions.

## Features
- **Multi-threaded Requests**: Supports executing multiple requests simultaneously to simulate high-load scenarios.
- **Flexible Configuration**: Allows specification of different batch sizes to test various levels of concurrency.
- **Detailed Metrics**: Option to print detailed request and response metrics for in-depth analysis.

## Prerequisites
Ensure you have Python installed on your system to run the script. This script is tested with Python 3.7 and above.

## Installation
Clone this repository or download the script directly into your preferred directory:
```bash
git clone https://github.com/yourrepository/Naive_OpenAI_bench.git
cd Naive_OpenAI_bench



